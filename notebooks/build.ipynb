{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6dc3571",
   "metadata": {},
   "source": [
    "## 1. Basic Setup\n",
    "\n",
    "Import required modules and initialize the container engine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8620799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from dbx_container.data.scraper import RuntimeScraper\n",
    "from dbx_container.engine import RuntimeContainerEngine\n",
    "from dbx_container.utils.logging import get_logger\n",
    "\n",
    "# Initialize logger\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Initialize the container engine\n",
    "engine = RuntimeContainerEngine(\n",
    "    data_dir=Path(\"../data/\"),\n",
    "    max_workers=5,\n",
    "    verify_ssl=False,\n",
    "    latest_lts_count=3,  # Only build latest 3 LTS versions\n",
    ")\n",
    "\n",
    "logger.info(\"Container engine initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7247d3",
   "metadata": {},
   "source": [
    "## 2. Fetch Runtime Information\n",
    "\n",
    "Fetch available runtimes from Databricks documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf8ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch runtime information\n",
    "logger.info(\"Fetching runtime information from Databricks...\")\n",
    "\n",
    "scraper = RuntimeScraper(verify_ssl=False)\n",
    "runtimes = scraper.get_supported_runtimes()\n",
    "\n",
    "logger.info(f\"Successfully fetched {len(runtimes)} runtimes\")\n",
    "\n",
    "# Filter LTS runtimes (non-ML)\n",
    "lts_runtimes = sorted(\n",
    "    [r for r in runtimes if \"LTS\" in r.version and not r.is_ml], key=lambda r: r.version, reverse=True\n",
    ")\n",
    "\n",
    "logger.info(f\"Found {len(lts_runtimes)} LTS runtimes\")\n",
    "logger.info(\"\\nLatest 3 LTS runtimes:\")\n",
    "for i, runtime in enumerate(lts_runtimes[:3], 1):\n",
    "    logger.info(\n",
    "        f\"  {i}. {runtime.version} (Python {runtime.system_environment.python_version}, {runtime.system_environment.operating_system})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90901919",
   "metadata": {},
   "source": [
    "## 3. Generate Dockerfiles for a Specific Runtime\n",
    "\n",
    "Build all image types for a specific runtime version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926631e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a specific runtime version\n",
    "target_version = \"17.3 LTS\"\n",
    "target_runtime = None\n",
    "\n",
    "for runtime in lts_runtimes:\n",
    "    if runtime.version == target_version:\n",
    "        target_runtime = runtime\n",
    "        break\n",
    "\n",
    "if target_runtime:\n",
    "    logger.info(f\"\\n[bold]Building images for {target_version}[/bold]\")\n",
    "\n",
    "    # Build all images for this runtime\n",
    "    generated_files = engine.build_all_images_for_runtime(\n",
    "        runtime=target_runtime,\n",
    "        registry=None,  # Use local tag, or specify registry like \"ghcr.io/username\"\n",
    "    )\n",
    "\n",
    "    # Display results\n",
    "    total_files = sum(len(files) for files in generated_files.values())\n",
    "    logger.info(f\"\\nSuccessfully generated {total_files} files across {len(generated_files)} image types\")\n",
    "\n",
    "    for image_type, files in generated_files.items():\n",
    "        if files:\n",
    "            logger.info(f\"\\n{image_type}:\")\n",
    "            for file in files[:2]:  # Show first 2 files\n",
    "                logger.info(f\"  - {file}\")\n",
    "            if len(files) > 2:\n",
    "                logger.info(f\"  ... and {len(files) - 2} more\")\n",
    "else:\n",
    "    logger.warning(f\"Runtime {target_version} not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de6bc4b",
   "metadata": {},
   "source": [
    "## 4. Build Non-Runtime-Specific Images\n",
    "\n",
    "Generate base images that don't depend on specific runtime versions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build base images (minimal, minimal-gpu)\n",
    "logger.info(\"\\n[bold]Building non-runtime-specific images...[/bold]\")\n",
    "\n",
    "base_files = engine.build_non_runtime_specific_images(registry=None)\n",
    "\n",
    "total_base_files = sum(len(files) for files in base_files.values())\n",
    "logger.info(f\"\\nGenerated {total_base_files} base image files\")\n",
    "\n",
    "for image_type, files in base_files.items():\n",
    "    logger.info(f\"\\n{image_type}: {len(files)} file(s)\")\n",
    "    for file in files:\n",
    "        logger.info(f\"  - {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8998ca3b",
   "metadata": {},
   "source": [
    "## 5. Build All Images for All Runtimes\n",
    "\n",
    "Generate Dockerfiles for all image types across the latest LTS runtimes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6578c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build everything (respecting latest_lts_count=3)\n",
    "logger.info(\"\\n[bold]Starting comprehensive Dockerfile generation...[/bold]\")\n",
    "logger.info(\"This will generate Dockerfiles for all image types across latest 3 LTS runtimes\\n\")\n",
    "\n",
    "all_generated_files = engine.build_all_images_for_all_runtimes(registry=None)\n",
    "\n",
    "# Display summary\n",
    "logger.print(\"\\n\" + \"=\" * 60)\n",
    "logger.print(\"[bold cyan]ðŸ“Š Build Summary[/bold cyan]\")\n",
    "logger.print(\"=\" * 60)\n",
    "\n",
    "total_files_count = 0\n",
    "for runtime_key, image_types in all_generated_files.items():\n",
    "    runtime_file_count = sum(len(files) for files in image_types.values())\n",
    "    total_files_count += runtime_file_count\n",
    "\n",
    "    logger.info(f\"\\n[bold]{runtime_key}[/bold] ({runtime_file_count} files)\")\n",
    "    for image_type, files in image_types.items():\n",
    "        if files:\n",
    "            logger.info(f\"  â€¢ {image_type}: {len(files)} file(s)\")\n",
    "\n",
    "logger.print(f\"\\n[bold green]âœ… Total: {total_files_count} files generated[/bold green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68436089",
   "metadata": {},
   "source": [
    "## 6. Generate Build Matrix for CI/CD\n",
    "\n",
    "Create a build matrix JSON file for GitHub Actions or other CI/CD pipelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d13bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Generate build matrix for CI/CD\n",
    "logger.info(\"\\n[bold]Generating build matrices for CI/CD...[/bold]\")\n",
    "\n",
    "# Full matrix (all runtimes, all image types)\n",
    "matrix_full = engine.generate_build_matrix(only_lts=False, image_type=None, latest_lts_count=None)\n",
    "logger.info(f\"\\nFull matrix: {len(matrix_full.get('include', []))} build configurations\")\n",
    "\n",
    "# LTS-only matrix\n",
    "matrix_lts = engine.generate_build_matrix(only_lts=True, image_type=None, latest_lts_count=None)\n",
    "logger.info(f\"LTS-only matrix: {len(matrix_lts.get('include', []))} build configurations\")\n",
    "\n",
    "# Latest 3 LTS with GPU images only\n",
    "matrix_gpu = engine.generate_build_matrix(only_lts=True, image_type=\"gpu\", latest_lts_count=3)\n",
    "logger.info(f\"Latest 3 LTS GPU matrix: {len(matrix_gpu.get('include', []))} build configurations\")\n",
    "\n",
    "# Latest 3 LTS with Python images only\n",
    "matrix_python = engine.generate_build_matrix(only_lts=True, image_type=\"python\", latest_lts_count=3)\n",
    "logger.info(f\"Latest 3 LTS Python matrix: {len(matrix_python.get('include', []))} build configurations\")\n",
    "\n",
    "# Display sample matrix entry\n",
    "if matrix_python.get(\"include\"):\n",
    "    logger.print(\"\\n[bold]Sample Matrix Entry (Python):[/bold]\")\n",
    "    logger.print(json.dumps(matrix_python[\"include\"][0], indent=2))\n",
    "\n",
    "# Save matrix to file\n",
    "matrix_path = Path(\"../data/build_matrix.json\")\n",
    "matrix_path.write_text(json.dumps(matrix_python, indent=2))\n",
    "logger.info(f\"\\nBuild matrix saved to: {matrix_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927f0741",
   "metadata": {},
   "source": [
    "## 7. Inspect Generated Files\n",
    "\n",
    "Examine the generated Dockerfiles and requirements files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdaaab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what directories were created\n",
    "data_dir = Path(\"../data\")\n",
    "image_type_dirs = [d for d in data_dir.iterdir() if d.is_dir() and d.name not in [\"__pycache__\", \"dbfsfuse\"]]\n",
    "\n",
    "logger.info(\"\\n[bold]Generated image type directories:[/bold]\")\n",
    "for img_dir in sorted(image_type_dirs):\n",
    "    runtime_dirs = [d for d in img_dir.iterdir() if d.is_dir()]\n",
    "    logger.info(f\"  â€¢ {img_dir.name}: {len(runtime_dirs)} runtime(s)\")\n",
    "\n",
    "# Inspect a Python Dockerfile\n",
    "python_dir = data_dir / \"python\"\n",
    "if python_dir.exists():\n",
    "    runtime_variants = list(python_dir.iterdir())\n",
    "    if runtime_variants:\n",
    "        variant_dir = runtime_variants[0]\n",
    "        dockerfile = variant_dir / \"Dockerfile\"\n",
    "\n",
    "        if dockerfile.exists():\n",
    "            logger.info(f\"\\n[bold]Dockerfile Preview:[/bold] {dockerfile.relative_to(data_dir)}\")\n",
    "            content = dockerfile.read_text()\n",
    "            lines = content.split(\"\\n\")\n",
    "\n",
    "            # Show first 25 lines\n",
    "            logger.print(\"\\n\" + \"\\n\".join(lines[:25]))\n",
    "            if len(lines) > 25:\n",
    "                logger.print(f\"\\n... ({len(lines) - 25} more lines)\")\n",
    "\n",
    "            logger.info(f\"\\nTotal: {len(content)} bytes, {len(lines)} lines\")\n",
    "\n",
    "        # Check for requirements.txt\n",
    "        requirements = variant_dir / \"requirements.txt\"\n",
    "        if requirements.exists():\n",
    "            logger.info(f\"\\n[bold]Requirements Preview:[/bold] {requirements.relative_to(data_dir)}\")\n",
    "            content = requirements.read_text()\n",
    "            lines = [l for l in content.split(\"\\n\") if l.strip() and not l.startswith(\"#\")]\n",
    "\n",
    "            # Show first 15 packages\n",
    "            logger.print(\"\\n\" + \"\\n\".join(lines[:15]))\n",
    "            if len(lines) > 15:\n",
    "                logger.print(f\"\\n... ({len(lines) - 15} more packages)\")\n",
    "\n",
    "            logger.info(f\"\\nTotal packages: {len(lines)}\")\n",
    "else:\n",
    "    logger.warning(\"No python directory found. Run the build examples first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e2229d",
   "metadata": {},
   "source": [
    "## 8. Advanced: Generate Single Dockerfile\n",
    "\n",
    "Generate a single Dockerfile for maximum control over the process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e76ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a single Dockerfile with full control\n",
    "if lts_runtimes:\n",
    "    target_runtime = lts_runtimes[0]\n",
    "    logger.info(f\"\\n[bold]Generating single Python Dockerfile for {target_runtime.version}[/bold]\")\n",
    "\n",
    "    # Get image configuration\n",
    "    config = engine.image_types.get(\"python\")\n",
    "\n",
    "    # Get runtime variations (different OS/Python combinations)\n",
    "    variations = engine.get_runtime_variations(target_runtime)\n",
    "    logger.info(f\"Found {len(variations)} variations for this runtime\")\n",
    "\n",
    "    if variations:\n",
    "        variation = variations[0]\n",
    "        logger.info(f\"Using variation: {variation['suffix']}\")\n",
    "\n",
    "        # Generate Dockerfile content\n",
    "        dockerfile_content = engine.generate_dockerfile_for_image_type(\n",
    "            runtime=target_runtime,\n",
    "            image_type=\"python\",\n",
    "            config=config,\n",
    "            variation=variation,\n",
    "            registry=None,  # or \"ghcr.io/myorg\"\n",
    "        )\n",
    "\n",
    "        # Save the Dockerfile\n",
    "        saved_path = engine.save_dockerfile(\n",
    "            dockerfile_content=dockerfile_content, runtime=target_runtime, image_type=\"python\", variation=variation\n",
    "        )\n",
    "\n",
    "        logger.info(f\"\\nDockerfile saved to: {saved_path}\")\n",
    "        logger.info(f\"Dockerfile size: {len(dockerfile_content)} bytes, {len(dockerfile_content.splitlines())} lines\")\n",
    "\n",
    "        # Preview the content\n",
    "        lines = dockerfile_content.split(\"\\n\")\n",
    "        logger.print(\"\\n[bold]Preview (first 20 lines):[/bold]\")\n",
    "        logger.print(\"\\n\".join(lines[:20]))\n",
    "        if len(lines) > 20:\n",
    "            logger.print(f\"\\n... ({len(lines) - 20} more lines)\")\n",
    "    else:\n",
    "        logger.warning(\"No variations found for this runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75e006b",
   "metadata": {},
   "source": [
    "## 9. Understanding Image Dependencies\n",
    "\n",
    "Visualize the dependency chain between different image types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9cdd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image dependency chains\n",
    "logger.print(\"\\n\" + \"=\" * 60)\n",
    "logger.print(\"[bold cyan]Image Dependency Chains[/bold cyan]\")\n",
    "logger.print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "# Standard chain\n",
    "logger.info(\"[bold]Standard Chain (CPU):[/bold]\")\n",
    "logger.info(\"  ubuntu:24.04\")\n",
    "logger.info(\"    â†“\")\n",
    "logger.info(\"  minimal (adds Java)\")\n",
    "logger.info(\"    â†“\")\n",
    "logger.info(\"  standard (adds FUSE, SSH)\")\n",
    "logger.info(\"    â†“\")\n",
    "logger.info(\"  python (adds Python env, packages)\")\n",
    "\n",
    "# GPU chain\n",
    "logger.info(\"\\n[bold]GPU Chain:[/bold]\")\n",
    "logger.info(\"  nvidia/cuda:11.8.0\")\n",
    "logger.info(\"    â†“\")\n",
    "logger.info(\"  minimal-gpu (adds Java)\")\n",
    "logger.info(\"    â†“\")\n",
    "logger.info(\"  standard-gpu (adds FUSE, SSH)\")\n",
    "logger.info(\"    â†“\")\n",
    "logger.info(\"  python-gpu (adds Python env, packages)\")\n",
    "\n",
    "# Standalone GPU\n",
    "logger.info(\"\\n[bold]Standalone GPU:[/bold]\")\n",
    "logger.info(\"  nvidia/cuda:11.8.0\")\n",
    "logger.info(\"    â†“\")\n",
    "logger.info(\"  gpu (adds Java, Spark, Python)\")\n",
    "\n",
    "logger.info(\"\\n[bold]Image Type Details:[/bold]\")\n",
    "for img_type, config in engine.image_types.items():\n",
    "    runtime_specific = \"Yes\" if config[\"runtime_specific\"] else \"No\"\n",
    "    depends_on = config.get(\"depends_on\") or \"None\"\n",
    "    logger.info(f\"\\n  â€¢ {img_type}\")\n",
    "    logger.info(f\"    Description: {config['description']}\")\n",
    "    logger.info(f\"    Depends on: {depends_on}\")\n",
    "    logger.info(f\"    Runtime-specific: {runtime_specific}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d37b069",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now you can:\n",
    "\n",
    "- Use the generated Dockerfiles to build container images\n",
    "- Integrate the build matrix into your CI/CD pipeline\n",
    "- Customize image types by modifying the engine configuration\n",
    "- See `list.ipynb` for runtime analysis and discovery examples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
